{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0e0f9f",
   "metadata": {},
   "source": [
    "# Doomed to failure: A history about target encoding and Tree-Based Algorithms\n",
    "---\n",
    "\n",
    "Have you ever worked with target encoders? Did you ever use any tree-based model? If you have worked with either there will likely be a time in which you are tempted to use both in the same pipeline for classifying data points with categorical features. DON'T! At least until you have read this article detailing one dangerous caveat that this combination has.\n",
    "\n",
    "In this article, I will guide you through the caveats that appear when a pipeline combines certain members of the family of target encoders with tree-based models and extremely low or high entropy features. I'll clue you in: data leakeages and overfitting issues will break your pipeline's performance. \n",
    "\n",
    "The good news is that these problems that we will see are easy to solve - just use CatBoost and let it handle the encoding methodology for you. As I will be arguing the encoder that it uses by default for categorical features magnificently handles categorical fetures with both extremely low and high entropies and is still in the realm of target encoding.\n",
    "\n",
    "**Important: to simplify the discussion we will frame the discussion under a binary classification task.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b59401",
   "metadata": {},
   "source": [
    "#### Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dcffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941fde2a",
   "metadata": {},
   "source": [
    "## Background Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0557f3",
   "metadata": {},
   "source": [
    "### Encoders\n",
    "\n",
    "Encoding methodologies aim to transform non-numerical categorical feature values into numerical values. There are multiple approaches and each comes with its own advantages and caveats. For instance, to mention a few of them:\n",
    "\n",
    "- **Label Encoding**: it simply assigns a unique integer to each category in the data.\n",
    "    *Pros:*\n",
    "    1. Simple\n",
    "\n",
    "    *Cons:*\n",
    "    1. May introduce ordinal relationships\n",
    "    2. Features with unknown amounts of categories which have high amounts of low-frecquency categories may be clustered into a marginal category, loosing predictive power based on them.\n",
    "\n",
    "- **One-Hot Encoding**: for each category seen for a feature, it creates a new dummy feature which simply indicates with 0 or 1 when the category appears.\n",
    "    *Pros:*\n",
    "    1. Simple\n",
    "    2. Does not assume order between categories\n",
    "\n",
    "    *Cons:*\n",
    "    1. Dimensionality may increase considerably making the use of a dimensionality reduction technique necessary and potentially exploding your system's memmory (tip: if you still want to use it check sparse matrices).\n",
    "    2. Computationally expensive.\n",
    "    3. Features with unknown amounts of categories which have high amounts of low-frecquency categories may be clustered into a marginal category, loosing predictive power based on them.\n",
    "\n",
    "- **Binary Encoding, Hashing Encodings and more. Let's not get carried out into an endless enumeration.**\n",
    "\n",
    "Importantly, encoding methodologies and classifier interact in different ways and consequently the resulting pipelines may inherit or develop different properties and caveats. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eadb1f5",
   "metadata": {},
   "source": [
    "### Target Encoders\n",
    "\n",
    "In its most basic form, a target encoder substitutes each category $c$ of a feature with the training set statistic \n",
    "$$\\frac{N_{positive\\_samples\\_with\\_category\\_c\\_for\\_the\\_feature}}{N_{\\text{all\\_samples\\_with\\_category\\_c\\_for\\_the\\_feature}}}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "towards-catboost-py3.11 (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
